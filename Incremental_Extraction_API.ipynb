{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extraccion Incremental de \"Crypto Historical Market Depth API\" de https://finage.co.uk/**\n",
    "En este caso, ya que con **\"Crypto Historical Market Depth API\"** se busca obtener los trades entre las fechas especificadas de alguna criptomoneda con el fin de realizar una serie historica, y dado el volumen de los datos (sería bastante grande si las fechas distan lo suficiente entre si y si la API permitiría realizar un mayor volumen de consultas gratuitamente), se decidió utilizar el Metodo Extracción de Tipo Incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo todas las Librerias que utilizaré\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from configparser import ConfigParser\n",
    "from utils_API import *\n",
    "from utils_state import *\n",
    "from utils_parquet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1577858542000 <class 'str'>\n",
      "1577862082000 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#Leo el archivo JSON metadata_ingestion.json que contiene el ultimo valor incremental extraído \n",
    "#de la API con read_state_from_json() de utils_state.py y lo guardo en la variable state\n",
    "state = read_state_from_json('metadata/metadata_ingestion.json')\n",
    "\n",
    "#Obtengo el último valor incremental del JSON devuelto por la API en la ultima consulta con get_last_incremental_value() \n",
    "#de utils_state.py y utilizo ese valor como fecha inicial con la que hare la query\n",
    "incremental_start_date = get_last_incremental_value(state, 'finage_API')\n",
    "\n",
    "#Convierto la fecha inicial de string a un objeto datetime\n",
    "incremental_start_date = datetime.strptime(incremental_start_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Asigno ese mismo obejeto a la fecha final y lo aumento en 1 hora con 'datetime.timedelta()' de datetime para \n",
    "#inicializar la fecha final con la que haré la query como 1 hora mas que la fecha inicial (asi lo pide la API)\n",
    "incremental_end_date = incremental_start_date + timedelta(minutes=59)\n",
    "\n",
    "#Les doy a la fecha final e inicial el formato indicado en la documentacion de la API\n",
    "#Para ello obtengo los timestamp correspondientes en milisegundos y los convierto en string\n",
    "incremental_start_date = str(int(incremental_start_date.timestamp() * 1000))\n",
    "incremental_end_date = str(int(incremental_end_date.timestamp() * 1000))\n",
    "\n",
    "#impresion de control\n",
    "print(incremental_start_date, type(incremental_start_date))\n",
    "print(incremental_end_date, type(incremental_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instancio ConfigParser() de configparser en la variable parser y con el leo el archivo de configuracion pipeline.conf\n",
    "parser = ConfigParser()\n",
    "parser.read('pipeline.conf')\n",
    "\n",
    "#Extraigo la informacion de la seccion 'finage' de pipeline.conf\n",
    "api_credentials = parser[\"finage\"]\n",
    "\n",
    "#Guardo la informacion extraida en sus variables correspondientes\n",
    "api_key = api_credentials[\"api_key\"]\n",
    "limit = api_credentials[\"limit\"] #El limite sera de 3 debido a que la API me permite solo 1.000 Requests por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establezco la url base y los parametros con la informacion extraida \n",
    "#de pipeline.conf para realizar la query segun la documentacion de la API\n",
    "base_url = \"https://api.finage.co.uk\"\n",
    "params = {'limit':limit,'apikey':api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol              p           q              t\n",
      "0  btcusd  7226.29000000  0.10698600  1577858543330\n",
      "1  btcusd  7226.39000000  0.00152700  1577858543668\n",
      "2  btcusd  7226.39000000  0.01347300  1577858545199\n",
      "   symbol             p           q              t\n",
      "0  ethusd  130.35000000  1.00000000  1577858543476\n",
      "1  ethusd  130.35000000  1.86800000  1577858545632\n",
      "2  ethusd  130.35000000  0.09010000  1577858546566\n",
      "   symbol           p              q              t\n",
      "0  adausd  0.03309000  1453.00000000  1577858599882\n",
      "1  adausd  0.03310000   342.60000000  1577858599888\n",
      "2  adausd  0.03309000   998.00000000  1577858600397\n",
      "    symbol           p              q              t\n",
      "0  dogeusd  0.00201430  5000.00000000  1577859669679\n",
      "1  dogeusd  0.00201470  7408.00000000  1577859669679\n",
      "2  dogeusd  0.00201470  6743.00000000  1577860398961\n"
     ]
    }
   ],
   "source": [
    "#Creo una lista con los simbolos de las criptomonedas, con montos \n",
    "#expresados en dolares, de las que solicitare los trades\n",
    "symbols = ['btcusd', 'ethusd', 'adausd', 'dogeusd']\n",
    "\n",
    "#Creo una lista donde guardare los dataframes con los trades de cada criptomoneda\n",
    "df_crypto_trades = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    #Modifico el endpoint para obtener informacion de los trades de cada criptomoneda en la lista symbols\n",
    "    endpoint = f\"history/crypto/depth/{symbol}/{incremental_start_date}/{incremental_end_date}\"\n",
    "\n",
    "    #hago la request con get_data() de utils_API.py\n",
    "    json_data = get_data(base_url, endpoint, params=params)\n",
    "\n",
    "    #Construyo un DataFrame con build_table() de utils_API.py \n",
    "    #usando la lista del JSON devuelto por la API\n",
    "    df_current_crypto_trades = build_table(json_data)\n",
    "\n",
    "    #Agrego la columna 'symbol' al DataFrame\n",
    "    df_current_crypto_trades['symbol'] = symbol\n",
    "\n",
    "    #Reordeno las columnas del DataFrame\n",
    "    columns = ['symbol', 'p', 'q', 't']\n",
    "\n",
    "    #Reindexo el DataFrame con las columnas en el nuevo orden para volverlo mas intuitivo\n",
    "    df_current_crypto_trades = df_current_crypto_trades.reindex(columns=columns)\n",
    "\n",
    "    #Impresion de control\n",
    "    print(df_current_crypto_trades)\n",
    "\n",
    "    #Agrego el dataframe de los ticks de la criptomoneda actual a la lista de dataframes df_crypto_ticks\n",
    "    df_crypto_trades.append(df_current_crypto_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.29000000</td>\n",
       "      <td>0.10698600</td>\n",
       "      <td>1577858543330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.39000000</td>\n",
       "      <td>0.00152700</td>\n",
       "      <td>1577858543668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.39000000</td>\n",
       "      <td>0.01347300</td>\n",
       "      <td>1577858545199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>1577858543476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>1.86800000</td>\n",
       "      <td>1577858545632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>0.09010000</td>\n",
       "      <td>1577858546566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03309000</td>\n",
       "      <td>1453.00000000</td>\n",
       "      <td>1577858599882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03310000</td>\n",
       "      <td>342.60000000</td>\n",
       "      <td>1577858599888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03309000</td>\n",
       "      <td>998.00000000</td>\n",
       "      <td>1577858600397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201430</td>\n",
       "      <td>5000.00000000</td>\n",
       "      <td>1577859669679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201470</td>\n",
       "      <td>7408.00000000</td>\n",
       "      <td>1577859669679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201470</td>\n",
       "      <td>6743.00000000</td>\n",
       "      <td>1577860398961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol              p              q              t\n",
       "0    btcusd  7226.29000000     0.10698600  1577858543330\n",
       "1    btcusd  7226.39000000     0.00152700  1577858543668\n",
       "2    btcusd  7226.39000000     0.01347300  1577858545199\n",
       "3    ethusd   130.35000000     1.00000000  1577858543476\n",
       "4    ethusd   130.35000000     1.86800000  1577858545632\n",
       "5    ethusd   130.35000000     0.09010000  1577858546566\n",
       "6    adausd     0.03309000  1453.00000000  1577858599882\n",
       "7    adausd     0.03310000   342.60000000  1577858599888\n",
       "8    adausd     0.03309000   998.00000000  1577858600397\n",
       "9   dogeusd     0.00201430  5000.00000000  1577859669679\n",
       "10  dogeusd     0.00201470  7408.00000000  1577859669679\n",
       "11  dogeusd     0.00201470  6743.00000000  1577860398961"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construyo un dataframe con todos los dataframes de cada criptomoneda \n",
    "#almacenados en df_cryptos con el metodo 'concat()' de pandas\n",
    "df_incremental = pd.concat(df_crypto_trades, ignore_index=True)\n",
    "df_incremental.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leo el archivo JSON metadata_ingestion.json que contiene el ultimo valor incremental extraído \n",
    "#de la API con read_state_from_json() de utils_state.py y lo guardo en la variable state\n",
    "state = read_state_from_json('metadata/metadata_ingestion.json')\n",
    "\n",
    "#Obtengo el mayor valor incremental del JSON devuelto por la API en la consulta actual con get_max_incremental_value() de utils_API.py.\n",
    "new_value = get_max_incremental_value(df_incremental['t'])\n",
    "\n",
    "#Actualizo el valor incremental del JSON en el estado de la replicación con update_incremental_value() de utils_state.py\n",
    "update_incremental_value(state, 'metadata/metadata_ingestion.json', 'finage_API', new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>t</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.29000000</td>\n",
       "      <td>0.10698600</td>\n",
       "      <td>2020-01-01 06:02:23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.39000000</td>\n",
       "      <td>0.00152700</td>\n",
       "      <td>2020-01-01 06:02:23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>btcusd</td>\n",
       "      <td>7226.39000000</td>\n",
       "      <td>0.01347300</td>\n",
       "      <td>2020-01-01 06:02:25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>2020-01-01 06:02:23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>1.86800000</td>\n",
       "      <td>2020-01-01 06:02:25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ethusd</td>\n",
       "      <td>130.35000000</td>\n",
       "      <td>0.09010000</td>\n",
       "      <td>2020-01-01 06:02:26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03309000</td>\n",
       "      <td>1453.00000000</td>\n",
       "      <td>2020-01-01 06:03:19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03310000</td>\n",
       "      <td>342.60000000</td>\n",
       "      <td>2020-01-01 06:03:19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adausd</td>\n",
       "      <td>0.03309000</td>\n",
       "      <td>998.00000000</td>\n",
       "      <td>2020-01-01 06:03:20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201430</td>\n",
       "      <td>5000.00000000</td>\n",
       "      <td>2020-01-01 06:21:09</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201470</td>\n",
       "      <td>7408.00000000</td>\n",
       "      <td>2020-01-01 06:21:09</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dogeusd</td>\n",
       "      <td>0.00201470</td>\n",
       "      <td>6743.00000000</td>\n",
       "      <td>2020-01-01 06:33:18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol              p              q                    t  hours\n",
       "0    btcusd  7226.29000000     0.10698600  2020-01-01 06:02:23      6\n",
       "1    btcusd  7226.39000000     0.00152700  2020-01-01 06:02:23      6\n",
       "2    btcusd  7226.39000000     0.01347300  2020-01-01 06:02:25      6\n",
       "3    ethusd   130.35000000     1.00000000  2020-01-01 06:02:23      6\n",
       "4    ethusd   130.35000000     1.86800000  2020-01-01 06:02:25      6\n",
       "5    ethusd   130.35000000     0.09010000  2020-01-01 06:02:26      6\n",
       "6    adausd     0.03309000  1453.00000000  2020-01-01 06:03:19      6\n",
       "7    adausd     0.03310000   342.60000000  2020-01-01 06:03:19      6\n",
       "8    adausd     0.03309000   998.00000000  2020-01-01 06:03:20      6\n",
       "9   dogeusd     0.00201430  5000.00000000  2020-01-01 06:21:09      6\n",
       "10  dogeusd     0.00201470  7408.00000000  2020-01-01 06:21:09      6\n",
       "11  dogeusd     0.00201470  6743.00000000  2020-01-01 06:33:18      6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convierto la columna 't' de timestamp a tipo datetime (se necesita agregar unit='ms' porque los timestamp son de tipo numpy.int64)\n",
    "df_incremental['t'] = pd.to_datetime(df_incremental['t'], unit='ms')\n",
    "\n",
    "#Formateo los timestamps en la columna 't' como fechas con el formato 'YYYY-mm-dd HH-MM-SS'\n",
    "df_incremental['t'] = df_incremental['t'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Creo la columna hours con las horas de los trades para particionar \n",
    "#al guardar en el dataframe posteriormente en formato parquet\n",
    "df_incremental['hours'] = pd.to_datetime(df_incremental['t']).dt.hour\n",
    "\n",
    "#Imprimo el nuevo DataFrame\n",
    "df_incremental.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Almacenamiento de los DataFrames en un Data Lake en formato Parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo la ruta en donde se almacenaran los archivos parquet\n",
    "bronze_dir = \"datalake/bronze/finage_api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el DataFrame de la extraccion incremental como archivo parquet con save_to_parquet() de utils_parquet.py \n",
    "#en el directorio Crypto_Historical_Market_Depth de finage_api de la capa bronze del Data Lake particionado por hora\n",
    "save_to_parquet(\n",
    "    df_incremental,\n",
    "    f\"{bronze_dir}/Crypto_Historical_Market_Depth\",\n",
    "    \"hours\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utn_env_de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
